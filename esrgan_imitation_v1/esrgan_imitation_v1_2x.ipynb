{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334f914c-d787-4c6c-a43a-4056d9f7b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import types\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image, rgb_to_grayscale\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "import os\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.spectral_norm as spectral_norm\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import glob\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a module for `torchvision.transforms.functional_tensor`\n",
    "functional_tensor = types.ModuleType(\"torchvision.transforms.functional_tensor\")\n",
    "functional_tensor.rgb_to_grayscale = rgb_to_grayscale\n",
    "\n",
    "# Add this module to sys.modules so other imports can access it\n",
    "sys.modules[\"torchvision.transforms.functional_tensor\"] = functional_tensor\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8896b28b-d9b8-41eb-8b23-11583349c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 16\n",
    "upscale_factor = 2  # Scale factor in generator\n",
    "lr_img_size = 64\n",
    "hr_img_size = lr_img_size * upscale_factor\n",
    "dataset_lenght = 10000\n",
    "lr = 0.0001\n",
    "gen_num_block = 6\n",
    "\n",
    "# === Step 1: Set Paths ===\n",
    "base_path = os.path.expanduser(\"~/real-esrgan-imitation-training-data\") \n",
    "lr_path = os.path.join(base_path, \"lr_images\")\n",
    "hr_path = os.path.join(base_path, f\"hr{'+' if upscale_factor==4 else ''}_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a0a8fd-d78a-46fa-99fb-5aa3fc6648f8",
   "metadata": {},
   "source": [
    "# Training Dataset Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6540d2c5-1724-4908-9f98-f78b387cd1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Creating dataset, as it's missing or incomplete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [03:38<00:00, 45.82image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Low-resolution images saved in: /Users/yusuf/real-esrgan-imitation-training-data/lr_images\n",
      "âœ… High-resolution images saved in: /Users/yusuf/real-esrgan-imitation-training-data/hr_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if dataset has already been created\n",
    "if not os.path.exists(lr_path) or not os.path.exists(hr_path) or len(os.listdir(lr_path)) == 0 or len(os.listdir(hr_path)) == 0:\n",
    "    print(\"ðŸš€ Creating dataset, as it's missing or incomplete...\")\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(lr_path, exist_ok=True)\n",
    "    os.makedirs(hr_path, exist_ok=True)\n",
    "    \n",
    "    # === Step 2: Get Device ===\n",
    "    def get_device():\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        elif torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        else:\n",
    "            return torch.device(\"cpu\")\n",
    "    \n",
    "    device = get_device()\n",
    "    \n",
    "    # === Step 3: Load Pretrained Real-ESRGAN Model ===\n",
    "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=6, num_grow_ch=32, scale=4).to(device)\n",
    "    \n",
    "    checkpoint = torch.load(\"../Real-ESRGAN/weights/RealESRGAN_x4plus_anime_6B.pth\", map_location=device)\n",
    "    if 'params_ema' in checkpoint:\n",
    "        model.load_state_dict(checkpoint[\"params_ema\"], strict=True)\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint, strict=True)\n",
    "    model.eval()\n",
    "    \n",
    "    # === Step 4: Load Kaggle Dataset ===\n",
    "    dataset_name = \"soumikrakshit/anime-faces\"\n",
    "    path = kagglehub.dataset_download(dataset_name)\n",
    "    dataset = dset.ImageFolder(root=path, \n",
    "                              transform=transforms.Compose([\n",
    "                                  transforms.Resize(64),\n",
    "                                  transforms.CenterCrop(64),\n",
    "                              ]))\n",
    "    \n",
    "    # === Step 5: Select 10,000 Random Images ===\n",
    "    image_indices = np.random.choice(len(dataset), size=dataset_lenght, replace=False)\n",
    "    \n",
    "    # === Step 6: Define Resizing Transformations ===\n",
    "    resize_transform_128 = transforms.Resize((128, 128))  # Downscale HR images to 128x128\n",
    "    \n",
    "    # === Step 7: Process and Save Images ===\n",
    "    for i in tqdm(range(1, dataset_lenght+1), desc=\"Processing Images\", unit=\"image\"):\n",
    "        idx = image_indices[i - 1]  # Ensure correct indexing\n",
    "    \n",
    "        # Load image\n",
    "        lr_image = dataset[idx][0]  # Low-resolution (64x64)\n",
    "        \n",
    "        # Convert to tensor & send to device\n",
    "        img_tensor = to_tensor(lr_image).unsqueeze(0).to(device)\n",
    "    \n",
    "        # Generate high-resolution image (256x256)\n",
    "        with torch.no_grad():\n",
    "            output_tensor = model(img_tensor).clamp(0,1)\n",
    "    \n",
    "        # Convert to PIL image\n",
    "        hr_image_256 = to_pil_image(output_tensor.squeeze(0))\n",
    "    \n",
    "        # Downscale to 128x128\n",
    "        hr_image_128 = resize_transform_128(hr_image_256)\n",
    "    \n",
    "        # Save images in ~/vision-project-images/\n",
    "        lr_image.save(os.path.join(lr_path, f\"{i}.png\"))  # Save as 64x64\n",
    "        hr_image_128.save(os.path.join(hr_path, f\"{i}.png\"))  # Save as 128x128\n",
    "    \n",
    "    print(f\"âœ… Low-resolution images saved in: {lr_path}\")\n",
    "    print(f\"âœ… High-resolution images saved in: {hr_path}\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"âœ… Dataset already exists. Skipping dataset creation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d11a03-608d-41f0-a337-12de8e218ceb",
   "metadata": {},
   "source": [
    "# Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea021d8a-7689-4118-b76e-49f5ab286276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for Anime Faces\n",
    "class AnimeFaceDataset(Dataset):\n",
    "    def __init__(self, lr_folder, hr_folder, lr_size=(64, 64), hr_size=(128, 128)):\n",
    "        self.lr_images = sorted(glob.glob(os.path.join(lr_folder, \"*.png\")))\n",
    "        self.hr_images = sorted(glob.glob(os.path.join(hr_folder, \"*.png\")))\n",
    "        \n",
    "        # Basic transforms\n",
    "        self.lr_transform = transforms.Compose([\n",
    "            transforms.Resize(lr_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        self.hr_transform = transforms.Compose([\n",
    "            transforms.Resize(hr_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.hr_images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lr_img = Image.open(self.lr_images[idx]).convert('RGB')\n",
    "        hr_img = Image.open(self.hr_images[idx]).convert('RGB')\n",
    "        \n",
    "        # Create low-resolution version\n",
    "        lr_img = self.lr_transform(hr_img)\n",
    "        \n",
    "        # Transform high-resolution image\n",
    "        hr_img = self.hr_transform(hr_img)\n",
    "        \n",
    "        return lr_img, hr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef74054-85a4-4b5b-bbec-7062c1b9a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AnimeFaceDataset(lr_path, hr_path, lr_size=(lr_img_size, lr_img_size), hr_size=(hr_img_size, hr_img_size))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ba6360-9ee4-4471-a65c-33e6769e7ee6",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fe1fe81-41ee-4026-b879-0225c910f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93df9897-ead7-4706-b4ee-1d4272878728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to initialize weights\n",
    "@torch.no_grad()\n",
    "def default_init_weights(module_list, scale=1, bias_fill=0, **kwargs):\n",
    "    if not isinstance(module_list, list):\n",
    "        module_list = [module_list]\n",
    "    for module in module_list:\n",
    "        for m in module.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, **kwargs)\n",
    "                m.weight.data *= scale\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, **kwargs)\n",
    "                m.weight.data *= scale\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)\n",
    "            elif isinstance(m, _BatchNorm):\n",
    "                init.constant_(m.weight, 1)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)\n",
    "\n",
    "# Pixel Unshuffle for downsampling\n",
    "def pixel_unshuffle(x, scale):\n",
    "    b, c, hh, hw = x.size()\n",
    "    out_channel = c * (scale**2)\n",
    "    assert hh % scale == 0 and hw % scale == 0\n",
    "    h = hh // scale\n",
    "    w = hw // scale\n",
    "    x_view = x.view(b, c, h, scale, w, scale)\n",
    "    return x_view.permute(0, 1, 3, 5, 2, 4).reshape(b, out_channel, h, w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca187fb1-d36c-489a-bbb5-e8170b510f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RRDBNet (Residual in Residual Dense Block Network) architecture\n",
    "class ResidualDenseBlock(nn.Module):\n",
    "    def __init__(self, channels=64, growth_channels=32):\n",
    "        super(ResidualDenseBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, growth_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels + growth_channels, growth_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(channels + 2 * growth_channels, growth_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(channels + 3 * growth_channels, growth_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(channels + 4 * growth_channels, channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        self.beta = 0.2  # Scaling factor\n",
    "        \n",
    "        # initialization\n",
    "        default_init_weights([self.conv1, self.conv2, self.conv3, self.conv4, self.conv5], 0.1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.lrelu(self.conv1(x))\n",
    "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
    "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
    "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
    "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
    "        return x5 * self.beta + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22697078-1bb8-423c-9114-a2cf50581f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRDB(nn.Module):\n",
    "    def __init__(self, channels=64):\n",
    "        super(RRDB, self).__init__()\n",
    "        self.rdb1 = ResidualDenseBlock(channels)\n",
    "        self.rdb2 = ResidualDenseBlock(channels)\n",
    "        self.rdb3 = ResidualDenseBlock(channels)\n",
    "        self.beta = 0.2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.rdb1(x)\n",
    "        out = self.rdb2(out)\n",
    "        out = self.rdb3(out)\n",
    "        return out * self.beta + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7c557fa-a94f-4228-8144-0b595df22308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_in_ch=3, num_out_ch=3, scale=2, num_feat=64, num_block=6, num_grow_ch=32):\n",
    "        super(Generator, self).__init__()\n",
    "        self.scale = scale\n",
    "        if scale == 2:\n",
    "            num_in_ch = num_in_ch * 4\n",
    "        elif scale == 1:\n",
    "            num_in_ch = num_in_ch * 16\n",
    "            \n",
    "        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)\n",
    "        self.body = nn.Sequential(*[RRDB(num_feat) for _ in range(num_block)])\n",
    "        self.conv_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
    "        \n",
    "        # upsample\n",
    "        self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
    "        self.conv_up2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
    "        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
    "        self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.scale == 2:\n",
    "            feat = pixel_unshuffle(x, scale=2)\n",
    "        elif self.scale == 1:\n",
    "            feat = pixel_unshuffle(x, scale=4)\n",
    "        else:\n",
    "            feat = x\n",
    "            \n",
    "        feat = self.conv_first(feat)\n",
    "        body_feat = self.conv_body(self.body(feat))\n",
    "        feat = feat + body_feat\n",
    "        \n",
    "        # upsample\n",
    "        feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
    "        feat = self.lrelu(self.conv_up2(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
    "        out = self.conv_last(self.lrelu(self.conv_hr(feat)))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95251ccc-9187-4a7e-99f8-5a6df4fd0056",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52122a23-5970-4d99-bd08-8a194ef39b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_input=3, num_feat=64, skip_connection=True):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.skip_connection = skip_connection\n",
    "        norm = spectral_norm\n",
    "        self.conv0 = nn.Conv2d(num_input, num_feat, 3, 1, 1)  # Assume the input image has a resolution of 256x256 (can also be 128x128)\n",
    "        self.conv1 = norm(nn.Conv2d(num_feat, num_feat * 2, 4, 2, 1, bias=False))  # 256x256 --> 128x128\n",
    "        self.conv2 = norm(nn.Conv2d(num_feat * 2, num_feat * 4, 4, 2, 1, bias=False))  # 128x128 --> 64x64\n",
    "        self.conv3 = norm(nn.Conv2d(num_feat * 4, num_feat * 8, 4, 2, 1, bias=False))  # 64x64 --> 32x32\n",
    "        self.conv4 = norm(nn.Conv2d(num_feat * 8, num_feat * 4, 3, 1, 1, bias=False))  # 32x32 --> 32x32\n",
    "        self.conv5 = norm(nn.Conv2d(num_feat * 4, num_feat * 2, 3, 1, 1, bias=False))  # 32x32 --> 32x32\n",
    "        self.conv6 = norm(nn.Conv2d(num_feat * 2, num_feat, 3, 1, 1, bias=False))  # 32x32 --> 32x32\n",
    "        self.conv7 = norm(nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=False))  # 32x32 --> 32x32\n",
    "        self.conv8 = norm(nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=False))  # 32x32 --> 32x32\n",
    "        self.conv9 = norm(nn.Conv2d(num_feat, 1, 3, 1, 1, bias=False))  # 32x32 --> 32x32\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = F.leaky_relu(self.conv0(x), 0.2, inplace=True)\n",
    "        y2 = F.leaky_relu(self.conv1(y1), 0.2, inplace=True)\n",
    "        y3 = F.leaky_relu(self.conv2(y2), 0.2, inplace=True)\n",
    "        y4 = F.leaky_relu(self.conv3(y3), 0.2, inplace=True)\n",
    "        y4 = F.interpolate(y4, scale_factor=2, mode='bilinear', align_corners=False)  # 32x32 --> 64x64\n",
    "        y5 = F.leaky_relu(self.conv4(y4), 0.2, inplace=True)\n",
    "        if self.skip_connection:\n",
    "            y5 = y5 + y3\n",
    "        y5 = F.interpolate(y5, scale_factor=2, mode='bilinear', align_corners=False)  # 64x64 --> 128x128\n",
    "        y6 = F.leaky_relu(self.conv5(y5), 0.2, inplace=True)\n",
    "        if self.skip_connection:\n",
    "            y6 = y6 + y2\n",
    "        y6 = F.interpolate(y6, scale_factor=2, mode='bilinear', align_corners=False)  # 128x128 --> 256x256\n",
    "        y7 = F.leaky_relu(self.conv6(y6), 0.2, inplace=True)\n",
    "        if self.skip_connection:\n",
    "            y7 = y7 + y1\n",
    "        y8 = F.leaky_relu(self.conv7(y7), 0.2, inplace=True)\n",
    "        y9 = F.leaky_relu(self.conv8(y8), 0.2, inplace=True)\n",
    "        out = self.conv9(y9)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407769e6-8b90-4b8b-ab64-5abde70a2826",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e2a8d22-e8ee-449c-98c1-0155ffe41ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = nn.BCEWithLogitsLoss().to(device)\n",
    "content_loss = nn.MSELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f80b9db8-932e-4c7c-af66-b0171e8cd513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relativistic_loss(real_pred, fake_pred):\n",
    "    real_loss = adversarial_loss(real_pred - torch.mean(fake_pred), torch.ones_like(real_pred))\n",
    "    fake_loss = adversarial_loss(fake_pred - torch.mean(real_pred), torch.zeros_like(fake_pred))\n",
    "    out = (real_loss + fake_loss) / 2\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "039cb312-d033-44ea-8aee-0fbf05119002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class perceptual_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(perceptual_loss, self).__init__()\n",
    "        # vgg = vgg19(pretrained=True)\n",
    "        vgg = vgg19(weights=VGG19_Weights.IMAGENET1K_V1)\n",
    "        self.feature_extractor = nn.Sequential(*list(vgg.features[:36])).eval()\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        x_features = self.feature_extractor(x)\n",
    "        target_features = self.feature_extractor(target)\n",
    "        loss = nn.functional.l1_loss(x_features, target_features)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58cabbbf-1ef7-4835-93ef-c569e86ae4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (conv_first): Conv2d(12, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (body): Sequential(\n",
       "    (0): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): RRDB(\n",
       "      (rdb1): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb2): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (rdb3): ResidualDenseBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_body): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_up1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_up2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_hr): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(num_in_ch=3, num_out_ch=3, scale=upscale_factor, num_feat=64, num_block=gen_num_block, num_grow_ch=32).to(device)\n",
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83f4389a-f082-4b7d-a932-cc3a08b36492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (conv2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (conv3): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (conv4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9db4cb27-8182-407d-9a44-289beccf5948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "perceptual_loss(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = perceptual_loss().to(device)\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98a006bf-cb16-4d24-99d1-26c9cf59ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c852388-febc-41c5-80eb-1ac817d51f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_g = optim.lr_scheduler.StepLR(optimizer_g, step_size=10, gamma=0.5)\n",
    "scheduler_d = optim.lr_scheduler.StepLR(optimizer_d, step_size = 10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "938631a8-cbad-4198-bfef-2ae0ae3df599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title=None):\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.figure(figsize=(12, 3))  # Set figure size\n",
    "\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb3fe3a-0f0b-4c1d-b8b4-01dfc1a8e37a",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016faec3-5d57-4477-832a-a94b216f83a0",
   "metadata": {},
   "source": [
    "we cleared the cell output becaseu it made the notebook 180 mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1eca6-1447-47c9-b334-5d4699f914ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    for batch_idx, (lr_images, hr_images) in enumerate(dataloader):\n",
    "        batch_start_time = time.time()\n",
    "        # Move images to device\n",
    "        lr_images = lr_images.to(device)\n",
    "        hr_images = hr_images.to(device)\n",
    "\n",
    "        # Create target labels for discriminator training\n",
    "        valid_labels = torch.ones((lr_images.size(0), 1, hr_images.size(2), hr_images.size(3)),\n",
    "                                    requires_grad=False).to(device)\n",
    "        fake_labels = torch.zeros((lr_images.size(0), 1, hr_images.size(2), hr_images.size(3)),\n",
    "                                   requires_grad=False).to(device)\n",
    "\n",
    "        # Generate super-resolved images from low-resolution images\n",
    "        sr_images = generator(lr_images)  # e.g. 64x64 --> 128x128 or 64x64 --> 256x256\n",
    "\n",
    "        # Clamp images to valid range [0, 1]\n",
    "        sr_images = torch.clamp(sr_images, 0, 1)\n",
    "        lr_images = torch.clamp(lr_images, 0, 1)\n",
    "\n",
    "        # ---------------------\n",
    "        # Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_d.zero_grad()  # Reset gradients for discriminator\n",
    "        real_preds = discriminator(hr_images)\n",
    "        fake_preds = discriminator(sr_images.detach())\n",
    "        d_loss = relativistic_loss(real_preds, fake_preds)\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # ---------------------\n",
    "        # Train Generator\n",
    "        # ---------------------\n",
    "        optimizer_g.zero_grad()  # Reset gradients for generator\n",
    "        fake_preds = discriminator(sr_images)\n",
    "        fake_preds = fake_preds.view_as(valid_labels)\n",
    "        g_adv_loss = adversarial_loss(fake_preds, valid_labels)\n",
    "        g_content_loss = content_loss(sr_images, hr_images)\n",
    "        g_perceptual_loss = feature_extractor(sr_images, hr_images)\n",
    "        g_loss = g_content_loss + g_adv_loss * 1e-3 + g_perceptual_loss * 1e-2\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        batch_end_time = time.time()\n",
    "        \n",
    "        if batch_idx % 5 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx}/{len(dataloader)}] ', end=\"=> \")\n",
    "            print(f'Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}', end=\", \")\n",
    "            print(f\"Batch Time: {(batch_end_time - batch_start_time):.4f}\")\n",
    "        \n",
    "        # Display images every 100 batches\n",
    "        if batch_idx % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                original_grid = torchvision.utils.make_grid(lr_images[:4].cpu(), nrow=4)\n",
    "                enhanced_grid = torchvision.utils.make_grid(sr_images[:4].cpu(), nrow=4)\n",
    "                imshow(original_grid, title='Original Images')\n",
    "                imshow(enhanced_grid, title='Enhanced Images')\n",
    "\n",
    "        # Cleanup to free memory\n",
    "        del fake_preds, g_adv_loss, g_content_loss, g_perceptual_loss, g_loss, sr_images, lr_images, hr_images\n",
    "        if device == torch.device(\"cuda\"):\n",
    "            torch.cuda.empty_cache()\n",
    "        elif device == torch.device(\"mps\"):\n",
    "            torch.mps.empty_cache()\n",
    "\n",
    "    # Update learning rate schedulers\n",
    "    scheduler_g.step()\n",
    "    scheduler_d.step()\n",
    "    epoch_end_time = time.time()\n",
    "    print(\"Epoch Time:\", epoch_end_time - epoch_start_time)\n",
    "\n",
    "    # Save model checkpoint\n",
    "    torch.save({\n",
    "        'generator_state_dict': generator.state_dict(),\n",
    "        'discriminator_state_dict': discriminator.state_dict(),\n",
    "        'optimizerG_state_dict': optimizer_g.state_dict(),\n",
    "        'optimizerD_state_dict': optimizer_d.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }, f'models/model_checkpoint_{upscale_factor}x_epoch_{epoch + 1}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7c10674-b4f6-47f5-9e2f-3770490a662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "  torch.save({\n",
    "    'generator_state_dict': generator.state_dict(),\n",
    "    'epoch': num_epochs,\n",
    "  }, f'models/final_generator_{upscale_factor}x.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e8ab3-fc5e-4a90-85da-209fcf38e3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
